{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install and load all necessary packages"
      ],
      "metadata": {
        "id": "4F1FMDKl1l7l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54SvWof7XGwM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim import matutils\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure you have the necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load & Preprocess data\n"
      ],
      "metadata": {
        "id": "LRVXm0Sr10aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We load data (a csv-file with ratings and content of TV series) from the Github repository\n",
        "url = \"https://raw.githubusercontent.com/valeriehase/Salamanca-CSS-SummerSchool/main/Processing%20text%20and%20text%20as%20data/data_tvseries.csv\"\n",
        "data = pd.read_csv(url, sep = \";\")"
      ],
      "metadata": {
        "id": "aHh51GXi6KGr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check data by inspecting first rows via head()\n",
        "data.head()"
      ],
      "metadata": {
        "id": "IRsKIIE4Bbb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the stop words and stemmer\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#Preprocess\n",
        "def clean_description_dfm(description):\n",
        "    # Tokenize the description\n",
        "    words = word_tokenize(description)\n",
        "    # Remove special signs and convert to lower case\n",
        "    words = [word.lower() for word in words if word.isalpha()]\n",
        "    # Remove stopwords\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    # Apply stemming\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    #Additionally re-join as string\n",
        "    return ' '.join(words)  # Join the tokens back into a single string\n",
        "\n",
        "tokens_dfm = [clean_description_dfm(description) for description in data[\"Description\"]]\n",
        "\n",
        "#Create a document-feature matrix, with relative pruning\n",
        "vectorizer = CountVectorizer(min_df = 0.004, max_df = .99)\n",
        "dfm = vectorizer.fit_transform(tokens_dfm)\n",
        "\n",
        "#Check result\n",
        "pd.DataFrame(dfm.todense(), columns = vectorizer.get_feature_names_out()).head()"
      ],
      "metadata": {
        "id": "yTY4jzLblPDU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Deciding on Model Parameters, here: K number of topics\n"
      ],
      "metadata": {
        "id": "zRjzaX8lhRbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistical Fit\n"
      ],
      "metadata": {
        "id": "hggB3Qe-e6oB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = matutils.Sparse2Corpus(dfm, documents_columns = False)\n",
        "dictionary = dict(enumerate(vectorizer.get_feature_names_out()))\n",
        "\n",
        "result = []\n",
        "for k in [4,6 ]:\n",
        "    m = LdaModel(\n",
        "        corpus,\n",
        "        num_topics = k,\n",
        "        id2word = dictionary,\n",
        "        random_state = 2024,\n",
        "    )\n",
        "    perplexity = m.log_perplexity(corpus)\n",
        "    coherence = CoherenceModel(\n",
        "        model = m, corpus = corpus, coherence = \"u_mass\"\n",
        "    ).get_coherence()\n",
        "    result.append(dict(k = k, perplexity = perplexity, coherence = coherence))\n",
        "\n",
        "result = pd.DataFrame(result)\n",
        "result.plot(x = \"k\", y=[\"perplexity\", \"coherence\"])\n",
        "plt.xticks([4, 6])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uhCK9WgYoF4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretability\n"
      ],
      "metadata": {
        "id": "nnLUDVqLibdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4K = LdaModel(corpus, num_topics = 4, id2word = dictionary, random_state = 2024)\n",
        "model_6K = LdaModel(corpus, num_topics = 6, id2word = dictionary, random_state = 2024)"
      ],
      "metadata": {
        "id": "Z4rCm-pbxc72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top Words\n"
      ],
      "metadata": {
        "id": "RbulU7SyigHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for K = 4\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        f\"Topic {n}\": [w for (w, tw) in words]\n",
        "        for (n, words) in model_4K.show_topics(formatted=False)\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "je-6TnCvx3T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for K = 6\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        f\"Topic {n}\": [w for (w, tw) in words]\n",
        "        for (n, words) in model_6K.show_topics(formatted=False)\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "sRsr9DQp0b2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top Documents\n"
      ],
      "metadata": {
        "id": "BpedK0lgimDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_representative_docs_for_topic(model, corpus, documents, topic_id, top_n = 5):\n",
        "    \"\"\"\n",
        "    Extract the most representative documents for a specific topic in an LDA model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained LdaModel object.\n",
        "    - corpus: The corpus used for training the LDA model.\n",
        "    - documents: The original documents corresponding to the corpus.\n",
        "    - topic_id: The topic ID for which to extract the most representative documents.\n",
        "    - top_n: The number of most representative documents to extract for the topic.\n",
        "\n",
        "    Returns:\n",
        "    - representative_docs: A list of the most representative documents for the specified topic.\n",
        "    \"\"\"\n",
        "    representative_docs = []\n",
        "\n",
        "    # Iterate over each document in the corpus\n",
        "    for doc_id, bow in enumerate(corpus):\n",
        "        # Get the topic distribution for the document\n",
        "        topic_distribution = model.get_document_topics(bow, minimum_probability=0)\n",
        "\n",
        "        # Store the document's topic probability for the specified topic\n",
        "        for tid, prob in topic_distribution:\n",
        "            if tid == topic_id:\n",
        "                representative_docs.append((doc_id, prob))\n",
        "\n",
        "    # Sort the documents for the specified topic by probability in descending order\n",
        "    representative_docs.sort(key=lambda x: x[1], reverse=True)\n",
        "    # Keep only the top_n most representative documents\n",
        "    representative_docs = representative_docs[:top_n]\n",
        "\n",
        "    # Convert document indices to actual documents\n",
        "    representative_docs = [documents[doc_id] for doc_id, _ in representative_docs]\n",
        "\n",
        "    return representative_docs\n",
        "\n",
        "# Get the most representative document for the 2nd topic (1st index, therefore topic_id = 1)\n",
        "representative_docs_for_topic = get_representative_docs_for_topic(model = model_4K, corpus = corpus, documents = data[\"Description\"], topic_id = 1, top_n = 1)\n",
        "\n",
        "# Print a representative documents for the  topic\n",
        "representative_docs_for_topic"
      ],
      "metadata": {
        "id": "1tRnfaQ51o-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the final model\n"
      ],
      "metadata": {
        "id": "dv7KnYBrflFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LdaModel(corpus, num_topics = 4, id2word = dictionary, random_state = 2024)"
      ],
      "metadata": {
        "id": "3bIdd6a14qSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check top words"
      ],
      "metadata": {
        "id": "wZ3Vjh7y1Ci5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check top words\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        f\"Topic {n}\": [w for (w, tw) in words]\n",
        "        for (n, words) in model_4K.show_topics(formatted=False)\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "2woJkMgZ4wGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check top documents per topic"
      ],
      "metadata": {
        "id": "oNUQqb6q1N1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the most representative document for first topic\n",
        "get_representative_docs_for_topic(model = model_4K, corpus = corpus,\n",
        "                                  documents = data[\"Description\"], topic_id = 0, top_n = 1)"
      ],
      "metadata": {
        "id": "G_0-BK8C3ax4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize topic proportions"
      ],
      "metadata": {
        "id": "0mbKebQN1mpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer topic distributions for each document\n",
        "topic_distributions = [model.get_document_topics(bow, minimum_probability = 0) for bow in corpus]\n",
        "\n",
        "# Aggregate topic proportions across the corpus\n",
        "num_topics = model.num_topics\n",
        "topic_proportions = np.zeros(num_topics)\n",
        "\n",
        "for doc_topics in topic_distributions:\n",
        "    for topic_id, prop in doc_topics:\n",
        "        topic_proportions[topic_id] += prop\n",
        "\n",
        "# Normalize to get proportions\n",
        "topic_proportions /= len(corpus)\n",
        "\n",
        "# Plot the topic proportions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(num_topics), topic_proportions, color='skyblue')\n",
        "plt.xlabel('Topic ID')\n",
        "plt.ylabel('Proportion')\n",
        "plt.title('Expected Topic Proportions Across the Corpus')\n",
        "plt.xticks(range(num_topics))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lXMSkBgL6XIm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}